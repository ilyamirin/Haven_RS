import os
import sys
import argparse
import json
from typing import Dict, Any, List, Optional

import pandas as pd

# We will reuse catalog/agents utilities from main.py to keep changes minimal
from main import read_agents, load_catalog, search_catalog

# LangChain (for prompt construction) + Transformers (for streaming)
from langchain_core.prompts import ChatPromptTemplate
from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer
import torch


class HFStreamer:
    """
    Minimal streaming chat wrapper over HuggingFace transformers.
    We still use LangChain's ChatPromptTemplate to construct prompts.
    """
    def __init__(self, model_name: Optional[str] = None, device: Optional[str] = None):
        self.model_name = model_name or os.environ.get('HF_MODEL', 'Qwen/Qwen3-4B-Instruct-2507')
        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_fast=True)
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_name,
            dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            device_map='auto' if torch.cuda.is_available() else None,
        )
        if device is None:
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            self.device = device
        if self.device == 'cpu':
            self.model = self.model.to('cpu')

    def stream_chat(self, system_prompt: str, user_prompt: str, max_new_tokens: int = 256):
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_prompt})
        try:
            inputs = self.tokenizer.apply_chat_template(messages, return_tensors="pt", add_generation_prompt=True)
        except Exception:
            prompt = (system_prompt + "\n\n" if system_prompt else "") + user_prompt
            inputs = self.tokenizer(prompt, return_tensors="pt")

        if isinstance(inputs, torch.Tensor):
            input_ids = inputs.to(self.model.device)
            attention_mask = torch.ones_like(input_ids)
        else:
            input_ids = inputs["input_ids"].to(self.model.device)
            attention_mask = inputs.get("attention_mask")
            if attention_mask is not None:
                attention_mask = attention_mask.to(self.model.device)

        streamer = TextIteratorStreamer(self.tokenizer, skip_prompt=True, skip_special_tokens=True)
        gen_kwargs = dict(
            input_ids=input_ids,
            attention_mask=attention_mask,
            max_new_tokens=max_new_tokens,
            do_sample=True,
            temperature=0.6,
            top_p=0.9,
            streamer=streamer,
        )

        import threading
        thread = threading.Thread(target=self.model.generate, kwargs=gen_kwargs)
        thread.start()
        for token in streamer:
            yield token
        thread.join()


def find_wardrobe_agent(agents: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    for a in agents:
        if 'wardrobe agent' in str(a.get('name', '')).lower():
            return a
    return agents[0] if agents else None


def print_stream(tokens_iter):
    buffer = ''
    for tok in tokens_iter:
        buffer += tok
        sys.stdout.write(tok)
        sys.stdout.flush()
    sys.stdout.write("\n")
    sys.stdout.flush()
    return buffer


def build_system_prompt(agent: Dict[str, Any], instruction: str) -> str:
    name = agent.get('name', 'Wardrobe Agent')
    persona = agent.get('persona', '')
    role = agent.get('role', '')
    extra = agent.get('prompt', '')
    return (
        f"–¢—ã ‚Äî {name}. {role}\n"
        f"–õ–∏—á–Ω–æ—Å—Ç—å: {persona}\n"
        f"–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: {extra}\n"
        f"{instruction}"
    )


def clarification_loop(agent: Dict[str, Any], llm: HFStreamer, query: str, catalog: pd.DataFrame, max_rounds: int = 3) -> str:
    refined_query = query.strip()
    for _ in range(max_rounds):
        shortlist = search_catalog(catalog, refined_query, top_k=5)
        preview = []
        if isinstance(shortlist, pd.DataFrame) and not shortlist.empty:
            cols = [c for c in ['name', 'brand', 'category', 'color', 'colors'] if c in shortlist.columns]
            for _, r in shortlist.head(5).iterrows():
                preview.append({c: str(r.get(c, '')) for c in cols})

        system_prompt = build_system_prompt(agent, (
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞ —Å–µ–π—á–∞—Å ‚Äî –∑–∞–¥–∞—Ç—å –¥–æ 3 —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —á—Ç–æ–±—ã —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –∫–∞—Ç–∞–ª–æ–≥—É.\n"
            "–ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –æ—Ü–µ–Ω–∏, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n"
            "–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –≤ JSON: {\"thoughts\": string, \"question\": string, \"need_more\": bool, \"refined_query\": string}.\n"
            "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —É—Å—Ç–∞–Ω–æ–≤–∏ need_more=false –∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π refined_query."
        ))
        human = (
            "–¢–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n"
            f"–¢–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å: {refined_query}\n"
            f"–ü—Ä–µ–≤—å—é –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (–¥–æ 5): {json.dumps(preview, ensure_ascii=False)}\n"
            "–°–Ω–∞—á–∞–ª–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏—è (thoughts), –∑–∞—Ç–µ–º –∑–∞–¥–∞–π 1 –∫–æ—Ä–æ—Ç–∫–∏–π –≤–æ–ø—Ä–æ—Å (question).\n"
            "–í–µ—Ä–Ω–∏ —Å—Ç—Ä–æ–≥–æ –æ–¥–∏–Ω JSON-–æ–±—ä–µ–∫—Ç."
        )
        # Use LangChain to build the prompt text (for formal compliance)
        prompt = ChatPromptTemplate.from_messages([
            ("system", "{system}"),
            ("human", "{human}"),
        ]).format(system=system_prompt, human=human)

        print(f"\n[{agent.get('name','Wardrobe Agent')}] –∑–∞–¥–∞—ë—Ç —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å‚Ä¶")
        buffer = print_stream(llm.stream_chat(system_prompt, human, max_new_tokens=280))

        thoughts = ''
        question = ''
        need_more = True
        candidate_query = refined_query
        try:
            start = buffer.find('{')
            end = buffer.rfind('}')
            if start != -1 and end != -1 and end > start:
                obj = json.loads(buffer[start:end+1])
                thoughts = str(obj.get('thoughts', '')).strip()
                question = str(obj.get('question', '')).strip()
                need_more = bool(obj.get('need_more', True))
                rq = str(obj.get('refined_query', '')).strip()
                if rq:
                    candidate_query = rq
        except Exception:
            question = buffer.strip()

        if thoughts:
            print(f"{agent.get('name','Wardrobe Agent')} ‚Äî –º—ã—Å–ª–∏:\n{thoughts}")
        if question:
            print(f"{agent.get('name','Wardrobe Agent')} ‚Äî –≤–æ–ø—Ä–æ—Å:\n{question}")

        print("–í–∞—à –æ—Ç–≤–µ—Ç (Enter ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å/–∑–∞–≤–µ—Ä—à–∏—Ç—å):")
        try:
            user_reply = input('> ').strip()
        except EOFError:
            user_reply = ''

        if user_reply:
            refined_query = (candidate_query + ' ' + user_reply).strip()
        else:
            refined_query = candidate_query

        if not need_more or not user_reply:
            break

    return refined_query or query


def final_recommendation(agent: Dict[str, Any], llm: HFStreamer, refined_query: str, catalog: pd.DataFrame, top_k: int = 10) -> Dict[str, Any]:
    shortlist = search_catalog(catalog, refined_query, top_k=top_k)
    items_preview = []
    if isinstance(shortlist, pd.DataFrame) and not shortlist.empty:
        # Collect compact dict for LLM context
        for _, r in shortlist.iterrows():
            d = {}
            for col, val in r.items():
                try:
                    s = '' if pd.isna(val) else str(val)
                except Exception:
                    s = ''
                if s:
                    d[col] = s
            items_preview.append(d)

    system_prompt = build_system_prompt(agent, (
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ –ª—É—á—à—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.\n"
        "–í–µ—Ä–Ω–∏ JSON: {\"thoughts\": string, \"answer\": string}."
    ))
    human = (
        f"–ò—Ç–æ–≥–æ–≤—ã–π —É—Ç–æ—á–Ω—ë–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {refined_query}\n"
        f"–ö–∞–Ω–¥–∏–¥–∞—Ç—ã (–¥–æ {top_k}): {json.dumps(items_preview[:top_k], ensure_ascii=False)}\n"
        "–°–Ω–∞—á–∞–ª–∞ –ø–æ–¥—É–º–∞–π (thoughts), –∑–∞—Ç–µ–º –¥–∞–π –∫—Ä–∞—Ç–∫–∏–π —Å–æ–≤–µ—Ç (answer). –í–µ—Ä–Ω–∏ –æ–¥–∏–Ω JSON-–æ–±—ä–µ–∫—Ç."
    )

    print(f"\n[{agent.get('name','Wardrobe Agent')}] —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é‚Ä¶")
    buffer = print_stream(llm.stream_chat(system_prompt, human, max_new_tokens=350))

    thoughts = ''
    answer = buffer.strip()
    try:
        start = buffer.find('{')
        end = buffer.rfind('}')
        if start != -1 and end != -1 and end > start:
            obj = json.loads(buffer[start:end+1])
            thoughts = str(obj.get('thoughts', '')).strip()
            answer = str(obj.get('answer', '')).strip() or answer
    except Exception:
        pass

    if thoughts:
        print(f"{agent.get('name','Wardrobe Agent')} ‚Äî –º—ã—Å–ª–∏:\n{thoughts}")
    if answer:
        print(f"{agent.get('name','Wardrobe Agent')} ‚Äî –æ—Ç–≤–µ—Ç:\n{answer}")

    # Return also raw shortlist to allow plain printing of items
    return {
        'thoughts': thoughts,
        'answer': answer,
        'shortlist': shortlist if isinstance(shortlist, pd.DataFrame) else pd.DataFrame(),
    }


def print_results_table(df: pd.DataFrame, top_k: int = 10):
    if df is None or df.empty:
        print("\n–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É.")
        return
    print("\n–¢–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∫–∞—Ç–∞–ª–æ–≥—É:")
    cols_order = [c for c in ['name', 'brand', 'category', 'color', 'colors', 'mark', 'keyword', 'kinds', 'description'] if c in df.columns]
    extra_cols = [c for c in df.columns if c not in cols_order and not c.startswith('_')]
    cols = cols_order + extra_cols
    for idx, (_, row) in enumerate(df.head(top_k).iterrows(), start=1):
        print(f"\n#{idx}")
        for c in cols:
            try:
                val = row.get(c, '')
            except Exception:
                val = ''
            if pd.isna(val) or str(val).strip() == '':
                continue
            print(f"{c}: {val}")


def print_banner(model_name: str, query: str):
    print("\n" + "-" * 61)
    print("–ü—Ä–æ—Å—Ç–æ–π –¥–∏–∞–ª–æ–≥ —Å Wardrobe Agent (LangChain + Transformers)")
    print("Haven is ready to dress you. üëîüß•üë¢")
    print(f"–ú–æ–¥–µ–ª—å: {model_name}")
    print(f"–ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {query}")
    print("-" * 61)


def main():
    parser = argparse.ArgumentParser(description="–ü—Ä–æ—Å—Ç–æ–π –¥–∏–∞–ª–æ–≥: Wardrobe Agent —É—Ç–æ—á–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç —Ç–æ–≤–∞—Ä—ã")
    parser.add_argument('--query', type=str, default=None, help='–ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è')
    parser.add_argument('--model', type=str, default=None, help='HF –º–æ–¥–µ–ª—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é Qwen/Qwen3-4B-Instruct-2507)')
    parser.add_argument('--max_clarify', type=int, default=3, help='–ú–∞–∫—Å–∏–º—É–º —É—Ç–æ—á–Ω—è—é—â–∏—Ö —Ä–∞—É–Ω–¥–æ–≤ Wardrobe Agent')
    parser.add_argument('--top_k', type=int, default=10, help='–°–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–∞—Ç–∞–ª–æ–≥–∞ –ø–æ–∫–∞–∑–∞—Ç—å')
    args = parser.parse_args()

    query = args.query
    if not query:
        print("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å (–Ω–∞–ø—Ä–∏–º–µ—Ä: –ò—â—É —Ç–µ–ø–ª—É—é —Ä—É–±–∞—à–∫—É –≤ –∫–ª–µ—Ç–∫—É –Ω–∞ –æ—Å–µ–Ω—å):")
        try:
            query = input('> ').strip()
        except EOFError:
            query = ''
    if not query:
        print("–ü—É—Å—Ç–æ–π –∑–∞–ø—Ä–æ—Å. –í—ã—Ö–æ–¥.")
        sys.exit(1)

    # Ensure default model per requirements
    model_name = args.model or os.environ.get('HF_MODEL') or 'Qwen/Qwen3-4B-Instruct-2507'
    os.environ['HF_MODEL'] = model_name

    agents = read_agents('agents_list.csv')
    if not agents:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å agents_list.csv")
        sys.exit(1)

    wardrobe = find_wardrobe_agent(agents)
    if not wardrobe:
        print("Wardrobe Agent –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ agents_list.csv")
        sys.exit(1)

    catalog = load_catalog(os.path.join('data', '27181_all_cards.csv'))
    if catalog is None or catalog.empty:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞—Ç–∞–ª–æ–≥ —Ç–æ–≤–∞—Ä–æ–≤ data/27181_all_cards.csv")
        sys.exit(1)

    llm = HFStreamer(model_name)

    print_banner(model_name, query)

    refined_query = clarification_loop(wardrobe, llm, query, catalog, max_rounds=args.max_clarify)
    outcome = final_recommendation(wardrobe, llm, refined_query, catalog, top_k=args.top_k)

    # Show catalog results
    shortlist = outcome.get('shortlist')
    if isinstance(shortlist, pd.DataFrame):
        print_results_table(shortlist, top_k=args.top_k)


if __name__ == '__main__':
    main()
